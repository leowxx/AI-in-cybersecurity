{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import subprocess\n",
    "import shlex\n",
    "import string\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import txtfileprocessing as txtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolizeAndVectorizeToFile(filevectors):\n",
    "    randomfile = \"/home/(username)/Workfiles/goodvectors2.txt\"\n",
    "    rf = open(randomfile,\"a+\")\n",
    "    #rf.write(json.dumps(numdict))\n",
    "    for i in range(0,len(filevectors)-1):\n",
    "        rf.write(\"%s,\" % str(filevectors[i]))\n",
    "    rf.write(str(filevectors[len(filevectors)-1]))\n",
    "    rf.write(\"\\n\")\n",
    "    #data = json.load(rf)\n",
    "    rf.close()\n",
    "\n",
    "def symbolizeAndVectorize(filetoopen):\n",
    "    keywordsfile = \"keywordsdict.txt\"\n",
    "    kfdread = open(keywordsfile,\"r+\")\n",
    "    keywords = json.load(kfdread)\n",
    "    \n",
    "    content = []\n",
    "    opcodes = []\n",
    "    filevectors = []\n",
    "    with open(filetoopen) as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "        #content - an array of lines from the file that was opened\n",
    "    for line in content:\n",
    "        if not (\"\\t\" in line):\n",
    "            continue\n",
    "        templist = line.split(\"\\t\")\n",
    "        tempstr = templist[2]\n",
    "        tempstr = \" \".join(tempstr.split())\n",
    "        templist = re.split(',',tempstr)\n",
    "        for i in range(0,len(templist)):\n",
    "            try:\n",
    "                hexnum = int(templist[i],16)\n",
    "                templist[i] = \"num\"\n",
    "            except ValueError:\n",
    "                continue\n",
    "        templist2 = templist[0].split()\n",
    "        opcodestr = templist2.pop(0)\n",
    "        opcodes.append(opcodestr)\n",
    "        \n",
    "        tempstr2 = \" \".join(templist2)\n",
    "        templist[0] = tempstr2\n",
    "        templist.insert(0,opcodestr)\n",
    "        operand1 = templist[1].split()\n",
    "        \n",
    "        operand2 = []\n",
    "        try:\n",
    "            operand2 = templist[2].split()\n",
    "        except IndexError:\n",
    "            operand2.append('')\n",
    "        lines = opcodes+operand1+operand2\n",
    "        opcodes = []\n",
    "        \n",
    "        for i in range(0,len(lines)):\n",
    "            if str(lines[i]).startswith(\"<\"):\n",
    "                lines[i] = \"num\"\n",
    "            elif str(lines[i]).startswith(\"[\"):\n",
    "                lines[i] = \"num\"\n",
    "            try:\n",
    "                hexnum = int(lines[i],16)\n",
    "                lines[i] = \"num\"\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        for j in range(len(lines)):\n",
    "            if lines[j] in keywords:\n",
    "                lines[j] = keywords[lines[j]]\n",
    "            if lines[j] != '':\n",
    "                filevectors.append(lines[j])\n",
    "        \n",
    "        \n",
    "    kfdread.close()\n",
    "    symbolizeAndVectorizeToFile(filevectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeFolder():\n",
    "    functype = \"good\"\n",
    "    #for path, dirs, files in os.walk(folderpath):\n",
    "    for path, dirs, files in os.walk(\"/home/(username)/Workfiles/TrainingFiles\"):\n",
    "        for file in files:\n",
    "            if(functype in file):\n",
    "                fullfilepath = path+\"/\"+file\n",
    "                symbolizeAndVectorize(filetovectorize)\n",
    "                \n",
    "vectorizeFolder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel():\n",
    "    # load json and create model\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def GetFunctions(file,path):\n",
    "    functions = []\n",
    "    processArg = \"readelf -SW \"+file\n",
    "    args = shlex.split(processArg)\n",
    "    output = subprocess.Popen(args,stdout=subprocess.PIPE,cwd=path ).communicate()[0]\n",
    "    out = output.decode('utf-8').split('\\n')\n",
    "    for item in out:\n",
    "        if(item.startswith(\".text.\",7)):\n",
    "            item = item[7:]\n",
    "            newitem = item[6:item.find(' ')]\n",
    "            functions.append(newitem)\n",
    "    return functions\n",
    "\n",
    "def GenerateAssemCodeFiles(functions,file,path):\n",
    "    localpath = \"/home/(username)/Workfiles/TrainingFiles/\"+file[:-2]\n",
    "    if not(os.path.exists(localpath)):\n",
    "        folderprocessArg = \"mkdir \"+file[:-2]\n",
    "        folderargs = shlex.split(folderprocessArg)\n",
    "        try:\n",
    "            folderout = subprocess.check_output(folderargs,cwd=\"/home/(username)/Workfiles/TrainingFiles\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"error while creating folder\")\n",
    "    filenames = []\n",
    "    for function in functions:\n",
    "        processArg = \"objdump -M intel -w -d --section=.text.\"+function+\" \"+file\n",
    "        args = shlex.split(processArg)\n",
    "        try:\n",
    "            out = subprocess.check_output(args,cwd=path)\n",
    "            filename = function+\".txt\"\n",
    "            filenames.append(filename)\n",
    "            filename = localpath+\"/\"+filename\n",
    "            #original path+ new folder+ new file's name\n",
    "            outfile = open(filename,'w')\n",
    "            outfile.write(out.decode(\"utf-8\"))\n",
    "            outfile.close()\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"error while creating .txt file\")\n",
    "    return filenames,localpath\n",
    "\n",
    "def CreateTxtFile(newpath):\n",
    "    for path, dirs, files in os.walk(newpath):\n",
    "        for file in files:\n",
    "            symbolizeAndVectorize(file,path)\n",
    "\n",
    "#Function to pad zeroes\n",
    "def trp(l, n):\n",
    "    return l[:n] + [0]*(n-len(l))\n",
    "\n",
    "def CreateCsvFile(newpath):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    fixedsize = 200\n",
    "    with open(newpath+\"/\"+\"vector.txt\",\"r\") as filletbread:\n",
    "        lines = [line.strip() for line in filletbread]\n",
    "        with open(newpath+\"/\"+\"vector.csv\",\"w\") as out_file:\n",
    "            codewriter = csv.writer(out_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for line in lines:\n",
    "                templist = [int(x.strip()) for x in line.split(',')]\n",
    "                \n",
    "                #Make the size of templist to be fixedsize\n",
    "                if (len(templist)<fixedsize):\n",
    "                    templist = trp(templist,fixedsize)\n",
    "                elif (len(templist)>fixedsize):\n",
    "                    templist = templist[:fixedsize]\n",
    "                \n",
    "                codewriter.writerow(templist)\n",
    "\n",
    "def EvalCsv(newpath):\n",
    "    keywordsfile = \"keywordsdict.txt\"\n",
    "    kfdread = open(keywordsfile,\"r\")\n",
    "    keywords = json.load(kfdread)\n",
    "    kfdread.close()\n",
    "    n_labels = len(keywords)+2\n",
    "    model = LoadModel()\n",
    "    testset = pd.read_csv(newpath+\"/\"+\"vector.csv\",header=None)\n",
    "    testx = testset.iloc[:, 0:].values\n",
    "\n",
    "    testx1 = numpy.eye(n_labels)[testx]\n",
    "\n",
    "    testy = model.predict_classes(testx1)\n",
    "    probability = model.predict_proba(testx1)\n",
    "\n",
    "    ysum = 0\n",
    "    probsum = 0\n",
    "    count=0\n",
    "    for i in range(0,len(testy)):\n",
    "        count+=1\n",
    "        ysum += testy[i]\n",
    "        probsum += probability[i]\n",
    "        print(\"X=%s, Predicted=%s\" % (testx1[i], testy[i]))\n",
    "        print(\"Probability=%s\"%(probability[i]))\n",
    "\n",
    "def ProcessSelectedFile(filepath):\n",
    "    pathlist = filepath.split(\"/\")\n",
    "    file = pathlist[-1]\n",
    "    pathlist2 = pathlist[1:-1]\n",
    "    path = '/'.join(pathlist2)\n",
    "    path = '/'+path\n",
    "    #print(file)\n",
    "    #print(path)\n",
    "    functions = []\n",
    "    if(file.endswith(\".o\")):\n",
    "        #functype = file[:-2]+\"_bad\"\n",
    "        #functions.append(\"main\") #To retrieve functype dynamically\n",
    "        functions = GetFunctions(file,path)\n",
    "    else:\n",
    "        print(\"Please select an object file\")\n",
    "    \"\"\"with open('CodeProcessor.ipynb','r') as codeprocessorfile:\n",
    "        codeprocessorread = codeprocessorfile.read()\n",
    "    codeprocessor = json.loads(codeprocessorread)\n",
    "    #Prepare a cell to process selected file\n",
    "    code_to_execute = compile(\"\\n\".join(codeprocessor[\"cells\"][1][\"source\"]),\"<string>\",\"exec\")\n",
    "    exec(code_to_execute)\"\"\"\n",
    "    return functions,file,path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, dirs, files in os.walk(\"/home/(username)/Desktop/cexamples/testcases/000\"):\n",
    "    for file in files:\n",
    "        #functype = file[:-2]+\"_bad\"\n",
    "        functype = \"main\"\n",
    "        if(file.endswith(\".o\")):\n",
    "            filepath = os.path.join(path, file)\n",
    "            functions,file1,path1 = ProcessSelectedFile(filepath)\n",
    "            filenames,newpath = GenerateAssemCodeFiles(functions,file1,path1)\n",
    "            #CreateTxtFile(newpath)\n",
    "            #CreateCsvFile(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"newfolder.o\"\n",
    "\n",
    "localpath = \"/home/(username)/Workfiles/TrainingFiles/\"+file[:-2]\n",
    "print(localpath)\n",
    "if not(os.path.exists(localpath)):\n",
    "    print(\"In here!\")\n",
    "    folderprocessArg = \"mkdir \"+file[:-2]\n",
    "    folderargs = shlex.split(folderprocessArg)\n",
    "    try:\n",
    "        folderout = subprocess.check_output(folderargs,cwd=\"/home/(username)/Workfiles/TrainingFiles\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"error while creating folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printfile(filetoprint):\n",
    "    keywordsfile = \"keywords.txt\"\n",
    "    kfread = open(keywordsfile,\"r+\")\n",
    "    keywords = kfread.read().splitlines()\n",
    "    keywords = list(filter(None, keywords))\n",
    "    kwlistsize = len(keywords)\n",
    "    #Reads the contents of the filetoprint, and store as an array\n",
    "    content = []\n",
    "    with open(filetoprint) as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "    #Check that for each line in content, opcodes that are not already in the opcodes array will be appended,\n",
    "    #and other words that are not registers or hexadecimal numbers will be added to instructions array.\n",
    "    for line in content:\n",
    "        if not (\"\\t\" in line):\n",
    "            continue\n",
    "        templist = line.split(\"\\t\")\n",
    "        tempstr = templist[2]\n",
    "        tempstr = \" \".join(tempstr.split())\n",
    "        templist = re.split(' |,',tempstr)\n",
    "        tempstr = templist[0]\n",
    "        if not(tempstr in keywords):\n",
    "            keywords.append(tempstr)\n",
    "        for i in range(1,len(templist)):\n",
    "            if not (templist[i] in keywords):\n",
    "                if not ((all(c in string.hexdigits for c in templist[i]))or(templist[i].startswith(\"<\"))or(templist[i].startswith(\"0x\"))):\n",
    "                    for j in keywords:\n",
    "                        if (j in templist[i]):\n",
    "                            break\n",
    "                    else:\n",
    "                        keywords.append(templist[i])\n",
    "    #Write opcodes array to opcodes file, write instructions array to instructions file\n",
    "    #Closing 2 files after writing\n",
    "    inputstring = \"\"\n",
    "    for i in range(kwlistsize,len(keywords)):\n",
    "        inputstring = inputstring + keywords[i] + \"\\n\"\n",
    "    kfread.write(inputstring)\n",
    "    kfread.close()\n",
    "    \n",
    "def printFolder():      \n",
    "    for path, dirs, files in os.walk(\"/home/(username)/Workfiles/TrainingFiles\"):\n",
    "        for file in files:\n",
    "            if(file.endswith(\".txt\")):\n",
    "                filetoprint = path+\"/\"+file\n",
    "                printfile(filetoprint)\n",
    "                \n",
    "#printFolder()\n",
    "\n",
    "def filetodictionary():\n",
    "    kwdict = {}\n",
    "    keywordsfile = \"keywords.txt\"\n",
    "    kfread = open(keywordsfile,\"r\")\n",
    "    keywords = kfread.read().splitlines()\n",
    "    keywords = list(filter(None,keywords))\n",
    "    kwlistsize = len(keywords)\n",
    "    kfread.close()\n",
    "    for i in range(0,kwlistsize):\n",
    "        kwdict[keywords[i]] = i+1\n",
    "    keywordsfile = \"keywordsdict.txt\"\n",
    "    kfdread = open(keywordsfile,\"w\")\n",
    "    kfdread.write(json.dumps(kwdict))\n",
    "    kfdread.close()\n",
    "    \n",
    "filetodictionary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsfile = \"keywordsdict.txt\"\n",
    "kfdread = open(keywordsfile,\"r\")\n",
    "keywords = json.load(kfdread)\n",
    "kfdread.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
